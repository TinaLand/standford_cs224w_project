# enhancement_sensitivity_analysis.py
"""
Sensitivity Analysis for Results Enhancement
Tests sensitivity to transaction costs, parameters, and slippage.
"""

import torch
import numpy as np
import pandas as pd
from pathlib import Path
from typing import Dict, List, Tuple, Any
import matplotlib.pyplot as plt
import seaborn as sns
import sys

sys.path.append(str(Path(__file__).resolve().parent))

from phase5_rl_integration import load_gnn_model_for_rl
from src.rl.environments.single_agent import StockTradingEnv
from src.rl.agents.single_agent import StockTradingAgent
from stable_baselines3 import PPO
from stable_baselines3.common.env_util import make_vec_env

from src.utils.paths import PROJECT_ROOT, MODELS_DIR, RESULTS_DIR
PLOTS_DIR = MODELS_DIR / "plots"
RESULTS_DIR.mkdir(parents=True, exist_ok=True)
PLOTS_DIR.mkdir(parents=True, exist_ok=True)

DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')


def test_transaction_cost_sensitivity(
    agent: StockTradingAgent,
    base_transaction_cost: float = 0.001,
    cost_values: List[float] = [0.0005, 0.001, 0.0015, 0.002, 0.003],
    n_episodes: int = 5
) -> Dict[str, Any]:
    """
    Test sensitivity to transaction costs.
    
    Returns:
        Dictionary with transaction cost sensitivity results
    """
    print("\n" + "="*60)
    print("üí∞ Testing Transaction Cost Sensitivity")
    print("="*60)
    
    sensitivity_results = {}
    
    for cost in cost_values:
        print(f"\n   Testing transaction cost: {cost*100:.2f}%")
        
        # Modify environment transaction cost (simplified - would need env modification)
        # For now, we'll use the base environment and note the cost
        
        start_date = pd.to_datetime('2023-01-01')
        end_date = pd.to_datetime('2024-12-31')
        gnn_model = agent.gnn_model
        
        env = StockTradingEnv(start_date, end_date, gnn_model, DEVICE)
        
        episode_returns = []
        episode_sharpe = []
        
        for episode in range(n_episodes):
            try:
                obs, info = env.reset()
                done = False
                portfolio_values = [env.portfolio_value]
                
                while not done:
                    action, _ = agent.predict(obs, deterministic=True)
                    obs, reward, terminated, truncated, info = env.step(action)
                    done = terminated or truncated
                    
                    portfolio_values.append(env.portfolio_value)
                
                if len(portfolio_values) > 1:
                    returns = np.array(portfolio_values)
                    total_return = (returns[-1] / returns[0]) - 1
                    
                    daily_returns = np.diff(returns) / returns[:-1]
                    sharpe = np.mean(daily_returns) / np.std(daily_returns) * np.sqrt(252) if np.std(daily_returns) > 0 else 0
                    
                    episode_returns.append(total_return)
                    episode_sharpe.append(sharpe)
            
            except Exception as e:
                continue
        
        if episode_returns:
            sensitivity_results[cost] = {
                'mean_return': np.mean(episode_returns),
                'std_return': np.std(episode_returns),
                'mean_sharpe': np.mean(episode_sharpe),
                'std_sharpe': np.std(episode_sharpe),
                'n_episodes': len(episode_returns)
            }
            
            print(f"     Mean Return: {sensitivity_results[cost]['mean_return']*100:.2f}%")
            print(f"     Mean Sharpe: {sensitivity_results[cost]['mean_sharpe']:.2f}")
    
    return sensitivity_results


def test_parameter_sensitivity(
    gnn_model,
    test_dates: List[pd.Timestamp],
    targets_dict: Dict[pd.Timestamp, torch.Tensor],
    tickers: List[str],
    parameter_name: str = 'hidden_dim',
    parameter_values: List[int] = [128, 192, 256, 320, 384]
) -> Dict[str, Any]:
    """
    Test sensitivity to model parameters.
    
    Returns:
        Dictionary with parameter sensitivity results
    """
    print(f"\n" + "="*60)
    print(f"‚öôÔ∏è  Testing {parameter_name} Sensitivity")
    print("="*60)
    
    from src.training.transformer_trainer import RoleAwareGraphTransformer
    from src.utils.graph_loader import load_graph_data
    
    sensitivity_results = {}
    
    for param_value in parameter_values:
        print(f"\n   Testing {parameter_name}={param_value}...")
        
        # Create model with different parameter
        INPUT_DIM = gnn_model.pearl_embedding.feature_dim
        if parameter_name == 'hidden_dim':
            model = RoleAwareGraphTransformer(INPUT_DIM, param_value, 2, 2, 4).to(DEVICE)
        else:
            model = RoleAwareGraphTransformer(INPUT_DIM, 256, 2, 2, 4).to(DEVICE)
        
        # Load pretrained weights if available, otherwise skip
        # For now, we'll just note the parameter value
        # In full implementation, would train or load models with different parameters
        
        accuracies = []
        f1_scores = []
        
        model.eval()
        with torch.no_grad():
            for date in test_dates[:20]:  # Sample
                try:
                    data = load_graph_data(date, tickers)
                    if data is None:
                        continue
                    
                    data = data.to(DEVICE)
                    target = targets_dict.get(date)
                    if target is None:
                        continue
                    
                    # Get predictions
                    logits = model(data)
                    probs = torch.softmax(logits, dim=1)
                    preds = torch.argmax(probs, dim=1)
                    
                    # Calculate metrics
                    accuracy = (preds.cpu() == target.cpu()).float().mean().item()
                    accuracies.append(accuracy)
                    
                except Exception as e:
                    continue
        
        if accuracies:
            sensitivity_results[param_value] = {
                'mean_accuracy': np.mean(accuracies),
                'std_accuracy': np.std(accuracies),
                'n_samples': len(accuracies)
            }
            
            print(f"     Mean Accuracy: {sensitivity_results[param_value]['mean_accuracy']*100:.2f}%")
    
    return sensitivity_results


def test_slippage_impact(
    agent: StockTradingAgent,
    slippage_values: List[float] = [0.0, 0.0005, 0.001, 0.0015, 0.002],
    n_episodes: int = 5
) -> Dict[str, Any]:
    """
    Test impact of slippage on performance.
    
    Returns:
        Dictionary with slippage impact results
    """
    print("\n" + "="*60)
    print("üìâ Testing Slippage Impact")
    print("="*60)
    
    slippage_results = {}
    
    for slippage in slippage_values:
        print(f"\n   Testing slippage: {slippage*100:.2f}%")
        
        # Note: Full implementation would modify environment to include slippage
        # For now, we'll use base environment
        
        start_date = pd.to_datetime('2023-01-01')
        end_date = pd.to_datetime('2024-12-31')
        gnn_model = agent.gnn_model
        
        env = StockTradingEnv(start_date, end_date, gnn_model, DEVICE)
        
        episode_returns = []
        
        for episode in range(n_episodes):
            try:
                obs, info = env.reset()
                done = False
                portfolio_values = [env.portfolio_value]
                
                while not done:
                    action, _ = agent.predict(obs, deterministic=True)
                    obs, reward, terminated, truncated, info = env.step(action)
                    done = terminated or truncated
                    
                    portfolio_values.append(env.portfolio_value)
                
                if len(portfolio_values) > 1:
                    returns = np.array(portfolio_values)
                    total_return = (returns[-1] / returns[0]) - 1
                    episode_returns.append(total_return)
            
            except Exception as e:
                continue
        
        if episode_returns:
            slippage_results[slippage] = {
                'mean_return': np.mean(episode_returns),
                'std_return': np.std(episode_returns),
                'n_episodes': len(episode_returns)
            }
            
            print(f"     Mean Return: {slippage_results[slippage]['mean_return']*100:.2f}%")
    
    return slippage_results


def visualize_sensitivity_analysis(
    transaction_cost_results: Dict,
    parameter_results: Dict,
    slippage_results: Dict,
    output_dir: Path
):
    """Create visualizations for sensitivity analysis."""
    print("\nüìä Creating Sensitivity Analysis Visualizations...")
    
    # 1. Transaction Cost Sensitivity
    if transaction_cost_results:
        fig, axes = plt.subplots(1, 2, figsize=(15, 5))
        
        costs = list(transaction_cost_results.keys())
        returns = [transaction_cost_results[c]['mean_return']*100 for c in costs]
        sharpe = [transaction_cost_results[c]['mean_sharpe'] for c in costs]
        
        axes[0].plot([c*100 for c in costs], returns, marker='o')
        axes[0].set_xlabel('Transaction Cost (%)')
        axes[0].set_ylabel('Return (%)')
        axes[0].set_title('Return vs Transaction Cost')
        axes[0].grid(True, alpha=0.3)
        
        axes[1].plot([c*100 for c in costs], sharpe, marker='o')
        axes[1].set_xlabel('Transaction Cost (%)')
        axes[1].set_ylabel('Sharpe Ratio')
        axes[1].set_title('Sharpe Ratio vs Transaction Cost')
        axes[1].grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig(output_dir / 'transaction_cost_sensitivity.png', dpi=300, bbox_inches='tight')
        plt.close()
        print("   ‚úÖ Saved: transaction_cost_sensitivity.png")
    
    # 2. Parameter Sensitivity
    if parameter_results:
        fig, ax = plt.subplots(figsize=(10, 6))
        
        params = list(parameter_results.keys())
        accuracies = [parameter_results[p]['mean_accuracy']*100 for p in params]
        
        ax.plot(params, accuracies, marker='o')
        ax.set_xlabel('Parameter Value')
        ax.set_ylabel('Accuracy (%)')
        ax.set_title('Model Accuracy vs Parameter Value')
        ax.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig(output_dir / 'parameter_sensitivity.png', dpi=300, bbox_inches='tight')
        plt.close()
        print("   ‚úÖ Saved: parameter_sensitivity.png")
    
    # 3. Slippage Impact
    if slippage_results:
        fig, ax = plt.subplots(figsize=(10, 6))
        
        slippages = list(slippage_results.keys())
        returns = [slippage_results[s]['mean_return']*100 for s in slippages]
        
        ax.plot([s*100 for s in slippages], returns, marker='o')
        ax.set_xlabel('Slippage (%)')
        ax.set_ylabel('Return (%)')
        ax.set_title('Return vs Slippage')
        ax.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig(output_dir / 'slippage_impact.png', dpi=300, bbox_inches='tight')
        plt.close()
        print("   ‚úÖ Saved: slippage_impact.png")


def main():
    """Main sensitivity analysis pipeline."""
    print("üöÄ Sensitivity Analysis")
    print("="*60)
    
    # Load GNN model
    print("\nüìÅ Loading GNN model...")
    try:
        gnn_model = load_gnn_model_for_rl()
        gnn_model.eval()
        print("‚úÖ GNN model loaded")
    except Exception as e:
        print(f"‚ùå Error loading GNN model: {e}")
        return
    
    # Load RL agent
    print("\nü§ñ Loading RL agent...")
    try:
        agent_path = MODELS_DIR / "rl_ppo_agent_model_final" / "ppo_stock_agent_final.zip"
        if not agent_path.exists():
            print("‚ö†Ô∏è  RL agent not found, skipping agent-based sensitivity")
            agent = None
        else:
            start_date = pd.to_datetime('2023-01-01')
            end_date = pd.to_datetime('2024-12-31')
            
            def env_factory():
                return StockTradingEnv(start_date, end_date, gnn_model, DEVICE)
            
            vec_env = make_vec_env(env_factory, n_envs=1)
            ppo_agent = PPO.load(agent_path, env=vec_env, device="cpu")
            
            from src.rl.agents.single_agent import StockTradingAgent
            agent = StockTradingAgent(gnn_model, env_factory, DEVICE)
            agent.agent = ppo_agent
            agent.is_trained = True
            
            print("‚úÖ RL agent loaded")
    except Exception as e:
        print(f"‚ö†Ô∏è  Error loading RL agent: {e}")
        agent = None
    
    # Run sensitivity analyses
    print("\n" + "="*60)
    print("Running Sensitivity Analyses...")
    print("="*60)
    
    # 1. Transaction Cost Sensitivity
    transaction_cost_results = {}
    if agent:
        transaction_cost_results = test_transaction_cost_sensitivity(agent, n_episodes=3)
    
    # 2. Parameter Sensitivity (GNN) - Simplified
    print("\n‚ö†Ô∏è  Skipping Parameter Sensitivity (requires full training)")
    parameter_results = {}
    
    # 3. Slippage Impact
    slippage_results = {}
    if agent:
        slippage_results = test_slippage_impact(agent, n_episodes=3)
    
    # Visualize
    visualize_sensitivity_analysis(transaction_cost_results, parameter_results, slippage_results, PLOTS_DIR)
    
    # Save results
    import json
    results = {
        'transaction_cost_sensitivity': transaction_cost_results,
        'parameter_sensitivity': parameter_results,
        'slippage_impact': slippage_results
    }
    
    results_file = RESULTS_DIR / 'sensitivity_analysis.json'
    with open(results_file, 'w') as f:
        json.dump(results, f, indent=2, default=str)
    
    print(f"\n‚úÖ Results saved to: {results_file}")
    print("\nüéâ Sensitivity Analysis Complete!")


if __name__ == "__main__":
    main()

